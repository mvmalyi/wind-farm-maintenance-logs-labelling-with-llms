{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6c7291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports of libraries and data \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# The Cleaned Dataset\n",
    "cleaned_df = pd.read_csv(\"updated_cleaned_data.csv\")\n",
    "\n",
    "# The Translated Dataset\n",
    "translated_df = pd.read_csv(\"translated_descriptors.csv\") # Prepare a translated dataset with English descriptions\n",
    "\n",
    "# Isolating the columns needed\n",
    "translated_df = translated_df[['WONUM', 'Description_EN', 'Observations_EN']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce40b2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the cleaned_df with translated_df on WONUM, keeping all rows from cleaned_df\n",
    "cleaned_df = cleaned_df.drop(columns=['Description_EN', 'Observations_EN'], errors='ignore')\n",
    "\n",
    "# Now merge with the translated data\n",
    "cleaned_df = cleaned_df.merge(translated_df[['WONUM', 'Description_EN', 'Observations_EN']], \n",
    "                              on='WONUM', \n",
    "                              how='left', \n",
    "                              suffixes=('', '_translated'))\n",
    "\n",
    "# Optional: Check for any failed merges (where translation was missing)\n",
    "missing_translations = cleaned_df[cleaned_df['Description_EN'].isna() | cleaned_df['Observations_EN'].isna()]\n",
    "if not missing_translations.empty:\n",
    "    print(f\"Warning: {len(missing_translations)} records are missing translations.\")\n",
    "    # Uncomment below to inspect\n",
    "    # print(missing_translations[['WONUM', 'Description_EN', 'Observations_EN']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec377b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Event Date to datetime\n",
    "cleaned_df['Event Date'] = pd.to_datetime(cleaned_df['Event Date'])\n",
    "\n",
    "# Reorder columns: Place Description_EN after Description, Observations_EN after Observations\n",
    "cols = cleaned_df.columns.tolist()\n",
    "new_cols = []\n",
    "inserted_desc_en = False\n",
    "inserted_obs_en = False\n",
    "\n",
    "for col in cols:\n",
    "    new_cols.append(col)\n",
    "    if col == 'Description' and 'Description_EN' in cols and not inserted_desc_en:\n",
    "        new_cols.append('Description_EN')\n",
    "        inserted_desc_en = True\n",
    "    elif col == 'Observations' and 'Observations_EN' in cols and not inserted_obs_en:\n",
    "        new_cols.append('Observations_EN')\n",
    "        inserted_obs_en = True\n",
    "\n",
    "# Remove duplicates while preserving order\n",
    "seen = set()\n",
    "final_cols = []\n",
    "for c in new_cols:\n",
    "    if c not in seen:\n",
    "        final_cols.append(c)\n",
    "        seen.add(c)\n",
    "\n",
    "# Reassign columns\n",
    "cleaned_df = cleaned_df[final_cols]\n",
    "\n",
    "# Sort by Event Date\n",
    "cleaned_df = cleaned_df.sort_values(by='Event Date', ascending=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f40e0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the updated cleaned DataFrame to a new CSV file\n",
    "cleaned_df.to_csv(\"input_dataset.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SCADA_Data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
